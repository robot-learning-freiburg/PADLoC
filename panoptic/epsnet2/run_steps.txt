[setup]
pip install torch==1.1 (make sure cuda=10 and nvidia driver is 4xx)
pip install -r requirements.txt
python setup.py install

[run]
multi-gpu
export PYTHONWARNINGS="ignore" #to stop warnings from flooding the console during evaluation

--pretrain start
python -m torch.distributed.launch --nproc_per_node=N_GPU train_panoptic.py --log_dir path/to/save/log/and/models path/to/config/files path/to/dataset --pre_train utility/efficientnet-b5-b6417697.pth

--resume start
python -m torch.distributed.launch --nproc_per_node=N_GPU train_panoptic.py --log_dir path/to/save/log/and/models path/to/config/files path/to/dataset --resume path/to/saved/model

--just eval  
python -m torch.distributed.launch --nproc_per_node=N_GPU train_panoptic.py --log_dir path/to/save/log/and/models path/to/config/files path/to/dataset --eval --resume path/to/saved/model

multi-gpu multi maching
python -m torch.distributed.launch --nproc_per_node=N_GPU --nnode=N_Nodes --node_rank=0_for_master_1_2_3_and_so_on_for_slave --master_addr=ip_of_master --master_port=port_of_master train_panoptic.py --log_dir path/to/save/log/and/models path/to/config/files path/to/dataset --pre_train utility/efficientnet-b5-b6417697.pth

[dataset]
python prepare_cityscapes.py path_to_city_folder path_for_output_folder
requires cityscapesscripts and pycococreatortools

python -m torch.distributed.launch --nproc_per_node=4 --nnode=4 --node_rank=3 --master_addr=10.164.0.14 --master_port=29500 train_panoptic.py --log_dir city_b7 config/city_panoptic.ini ../../seam/ --pre_train utility/efficientnet-b6-c76e70fd.pth 


use it before running training to avoid training gets stuck problem
export NCCL_LL_THRESHOLD=0
